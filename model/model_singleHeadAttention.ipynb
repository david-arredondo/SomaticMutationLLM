{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 \t BINARYdata_CANCER_TYPE_0MinMutations_1696MinCancerType.csv\n",
      "28 \t BINARYdata_CANCER_TYPE_0MinMutations_169MinCancerType.csv\n",
      "2 \t BINARYdata_CANCER_TYPE_3MinMutations_1696MinCancerType.csv\n",
      "39 \t BINARYdata_CANCER_TYPE_3MinMutations_169MinCancerType.csv\n",
      "14 \t BINARYdata_CANCER_TYPE_DETAILED_0MinMutations_1696MinCancerType.csv\n",
      "31 \t BINARYdata_CANCER_TYPE_DETAILED_0MinMutations_169MinCancerType.csv\n",
      "12 \t BINARYdata_CANCER_TYPE_DETAILED_3MinMutations_1696MinCancerType.csv\n",
      "35 \t BINARYdata_CANCER_TYPE_DETAILED_3MinMutations_169MinCancerType.csv\n",
      "47 \t canonical_ref_barcode_refIdxs_map.pkl\n",
      "27 \t data_CANCER_TYPE_0MinMutations_1696MinCancerType.csv\n",
      "29 \t data_CANCER_TYPE_0MinMutations_169MinCancerType.csv\n",
      "52 \t data_CANCER_TYPE_3MinMutations_1696MinCancerType.csv\n",
      "21 \t data_CANCER_TYPE_3MinMutations_169MinCancerType.csv\n",
      "13 \t data_CANCER_TYPE_DETAILED_0MinMutations_1696MinCancerType.csv\n",
      "33 \t data_CANCER_TYPE_DETAILED_0MinMutations_169MinCancerType.csv\n",
      "3 \t data_CANCER_TYPE_DETAILED_3MinMutations_1696MinCancerType.csv\n",
      "56 \t data_CANCER_TYPE_DETAILED_3MinMutations_169MinCancerType.csv\n",
      "41 \t label_mappings\n",
      "36 \t top100_BINARYdata_CANCER_TYPE_0MinMutations_1603MinCancerType.csv\n",
      "26 \t top100_BINARYdata_CANCER_TYPE_0MinMutations_160MinCancerType.csv\n",
      "50 \t top100_BINARYdata_CANCER_TYPE_3MinMutations_1603MinCancerType.csv\n",
      "0 \t top100_BINARYdata_CANCER_TYPE_3MinMutations_160MinCancerType.csv\n",
      "6 \t top100_BINARYdata_CANCER_TYPE_DETAILED_0MinMutations_1603MinCancerType.csv\n",
      "54 \t top100_BINARYdata_CANCER_TYPE_DETAILED_0MinMutations_160MinCancerType.csv\n",
      "1 \t top100_BINARYdata_CANCER_TYPE_DETAILED_3MinMutations_1603MinCancerType.csv\n",
      "25 \t top100_BINARYdata_CANCER_TYPE_DETAILED_3MinMutations_160MinCancerType.csv\n",
      "7 \t top100_data_CANCER_TYPE_0MinMutations_1603MinCancerType.csv\n",
      "51 \t top100_data_CANCER_TYPE_0MinMutations_160MinCancerType.csv\n",
      "46 \t top100_data_CANCER_TYPE_0MinMutations_1696MinCancerType.csv\n",
      "17 \t top100_data_CANCER_TYPE_0MinMutations_169MinCancerType.csv\n",
      "38 \t top100_data_CANCER_TYPE_3MinMutations_1603MinCancerType.csv\n",
      "37 \t top100_data_CANCER_TYPE_3MinMutations_160MinCancerType.csv\n",
      "49 \t top100_data_CANCER_TYPE_3MinMutations_1696MinCancerType.csv\n",
      "48 \t top100_data_CANCER_TYPE_3MinMutations_169MinCancerType.csv\n",
      "15 \t top100_data_CANCER_TYPE_DETAILED_0MinMutations_1603MinCancerType.csv\n",
      "24 \t top100_data_CANCER_TYPE_DETAILED_0MinMutations_160MinCancerType.csv\n",
      "9 \t top100_data_CANCER_TYPE_DETAILED_0MinMutations_1696MinCancerType.csv\n",
      "5 \t top100_data_CANCER_TYPE_DETAILED_0MinMutations_169MinCancerType.csv\n",
      "30 \t top100_data_CANCER_TYPE_DETAILED_3MinMutations_1603MinCancerType.csv\n",
      "20 \t top100_data_CANCER_TYPE_DETAILED_3MinMutations_160MinCancerType.csv\n",
      "42 \t top100_data_CANCER_TYPE_DETAILED_3MinMutations_1696MinCancerType.csv\n",
      "44 \t top100_data_CANCER_TYPE_DETAILED_3MinMutations_169MinCancerType.csv\n",
      "40 \t top10_BINARYdata_CANCER_TYPE_0MinMutations_1213MinCancerType.csv\n",
      "55 \t top10_BINARYdata_CANCER_TYPE_0MinMutations_121MinCancerType.csv\n",
      "19 \t top10_BINARYdata_CANCER_TYPE_3MinMutations_1213MinCancerType.csv\n",
      "34 \t top10_BINARYdata_CANCER_TYPE_3MinMutations_121MinCancerType.csv\n",
      "57 \t top10_BINARYdata_CANCER_TYPE_DETAILED_0MinMutations_1213MinCancerType.csv\n",
      "53 \t top10_BINARYdata_CANCER_TYPE_DETAILED_0MinMutations_121MinCancerType.csv\n",
      "23 \t top10_BINARYdata_CANCER_TYPE_DETAILED_3MinMutations_1213MinCancerType.csv\n",
      "10 \t top10_BINARYdata_CANCER_TYPE_DETAILED_3MinMutations_121MinCancerType.csv\n",
      "45 \t top10_data_CANCER_TYPE_0MinMutations_1696MinCancerType.csv\n",
      "11 \t top10_data_CANCER_TYPE_0MinMutations_169MinCancerType.csv\n",
      "18 \t top10_data_CANCER_TYPE_3MinMutations_1696MinCancerType.csv\n",
      "8 \t top10_data_CANCER_TYPE_3MinMutations_169MinCancerType.csv\n",
      "4 \t top10_data_CANCER_TYPE_DETAILED_0MinMutations_1696MinCancerType.csv\n",
      "32 \t top10_data_CANCER_TYPE_DETAILED_0MinMutations_169MinCancerType.csv\n",
      "22 \t top10_data_CANCER_TYPE_DETAILED_3MinMutations_1696MinCancerType.csv\n",
      "16 \t top10_data_CANCER_TYPE_DETAILED_3MinMutations_169MinCancerType.csv\n",
      "\n",
      " data_CANCER_TYPE_3MinMutations_169MinCancerType.csv\n"
     ]
    }
   ],
   "source": [
    "from custom_dataset import custom_collate, Dataset_MutationList, Dataset_TopN_emb\n",
    "from models import *\n",
    "\n",
    "# LOAD DATA\n",
    "# canonical_mut_embeddings_esm2 = np.load('../aa/canonical_mut_embeddings_esm2.npy')\n",
    "canonical_ave_embeddings_esm2 = np.load('../aa/canonical_mut_average_embeddings_esm2.npy')\n",
    "data_dir = '../labeled_data/'\n",
    "labeled_data = os.listdir(data_dir)\n",
    "for ni,i in sorted(zip(labeled_data,range(len(labeled_data)))):print(i,'\\t',ni)\n",
    "data = labeled_data[21]\n",
    "print('\\n',data)\n",
    "data_df = pd.read_csv(data_dir+data)\n",
    "nlabels = len(data_df['int_label'].unique())\n",
    "device = 'cuda:1'\n",
    "\n",
    "# Create dataset\n",
    "# dataset = Dataset_MutationList(data_df, canonical_mut_embeddings_esm2,device)\n",
    "dataset = Dataset_MutationList(data_df, canonical_ave_embeddings_esm2,device)\n",
    "\n",
    "# Create DataLoader\n",
    "# dataloader = DataLoader(dataset, batch_size=100, shuffle=False, collate_fn=custom_collate)\n",
    "\n",
    "## TEST/TRAIN SPLIT\n",
    "test_size = .2\n",
    "random_state = 42\n",
    "batch_size = 1\n",
    "indices = list(range(len(dataset)))\n",
    "\n",
    "train_indices, test_indices = train_test_split(\n",
    "    indices, \n",
    "    test_size=test_size, \n",
    "    random_state=random_state\n",
    ")\n",
    "\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "test_dataset = Subset(dataset, test_indices)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=custom_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0708, -0.1004,  0.0965,  ...,  0.1381, -0.3298,  0.6028],\n",
       "         [-0.1024,  0.2950,  0.1107,  ...,  0.1083, -0.1077, -0.1759],\n",
       "         [ 0.0956, -0.0093,  0.0032,  ..., -0.3538, -0.6821, -0.0153],\n",
       "         ...,\n",
       "         [ 0.0572,  0.3157,  0.0624,  ...,  0.1077, -0.0975, -0.1868],\n",
       "         [-0.2116, -0.0350,  0.3335,  ...,  0.1835, -0.1566,  0.2194],\n",
       "         [-0.0313, -0.5568, -0.0538,  ...,  0.1537, -0.4635,  0.0801]],\n",
       "        device='cuda:1'),\n",
       " tensor(34, device='cuda:1'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.16158075053780574"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# majority classifier\n",
    "print(len(data_df['int_label'].unique()))\n",
    "sorted(data_df['int_label'].value_counts(),reverse=True)[0]/len(data_df['int_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n labels: 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAINING:   0%|          | 18/90367 [00:00<17:06, 88.00it/s, Epoch=1/100, Loss: 11.4872] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAINING:  22%|██▏       | 20024/90367 [02:15<08:20, 140.50it/s, Epoch=1/100, Loss: 20.4324] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAINING:  44%|████▍     | 40024/90367 [04:39<05:59, 140.00it/s, Epoch=1/100, Loss: 6.3390]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAINING:  66%|██████▋   | 60023/90367 [07:00<03:34, 141.58it/s, Epoch=1/100, Loss: 3.2201]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAINING:  89%|████████▊ | 80018/90367 [09:20<01:13, 141.28it/s, Epoch=1/100, Loss: 0.7634]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAINING: 100%|██████████| 90367/90367 [10:32<00:00, 142.76it/s, Epoch=1/100, Loss: 1.1416]   \n",
      "TESTING: 100%|██████████| 22592/22592 [00:29<00:00, 755.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 17.00%, (3841 of 22592)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAINING:   0%|          | 14/90367 [00:00<10:48, 139.27it/s, Epoch=2/100, Loss: 3.6020]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAINING:  22%|██▏       | 20024/90367 [02:19<08:14, 142.21it/s, Epoch=2/100, Loss: 7.8013] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAINING:  44%|████▍     | 40019/90367 [04:39<05:54, 141.98it/s, Epoch=2/100, Loss: 4.4054] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAINING:  66%|██████▋   | 60020/90367 [07:02<03:38, 138.99it/s, Epoch=2/100, Loss: 0.7893]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAINING:  89%|████████▊ | 80030/90367 [09:23<01:10, 146.78it/s, Epoch=2/100, Loss: 2.6929] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAINING: 100%|██████████| 90367/90367 [10:36<00:00, 141.88it/s, Epoch=2/100, Loss: 0.0097] \n",
      "TESTING: 100%|██████████| 22592/22592 [00:29<00:00, 754.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 21.98%, (4966 of 22592)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAINING:   0%|          | 14/90367 [00:00<10:58, 137.22it/s, Epoch=3/100, Loss: 3.5505] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAINING:  22%|██▏       | 20028/90367 [02:22<08:21, 140.29it/s, Epoch=3/100, Loss: 3.7563] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAINING:  44%|████▍     | 40016/90367 [04:43<06:00, 139.82it/s, Epoch=3/100, Loss: 2.3600]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAINING:  66%|██████▋   | 60023/90367 [07:07<03:35, 140.56it/s, Epoch=3/100, Loss: 0.0119] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAINING:  89%|████████▊ | 80015/90367 [09:30<01:14, 139.47it/s, Epoch=3/100, Loss: 3.1353]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAINING: 100%|██████████| 90367/90367 [10:44<00:00, 140.29it/s, Epoch=3/100, Loss: 4.6895] \n",
      "TESTING: 100%|██████████| 22592/22592 [00:29<00:00, 756.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 25.57%, (5776 of 22592)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAINING:   0%|          | 14/90367 [00:00<11:00, 136.84it/s, Epoch=4/100, Loss: 0.3324]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAINING:  22%|██▏       | 20016/90367 [02:23<08:27, 138.52it/s, Epoch=4/100, Loss: 3.4461] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAINING:  44%|████▍     | 40023/90367 [04:46<06:00, 139.77it/s, Epoch=4/100, Loss: 2.7909]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAINING:  66%|██████▋   | 60021/90367 [07:06<03:19, 152.18it/s, Epoch=4/100, Loss: 0.1673]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAINING:  89%|████████▊ | 80021/90367 [09:18<01:08, 151.99it/s, Epoch=4/100, Loss: 1.6238] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAINING: 100%|██████████| 90367/90367 [10:26<00:00, 144.24it/s, Epoch=4/100, Loss: 2.2540] \n",
      "TESTING: 100%|██████████| 22592/22592 [00:29<00:00, 761.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 29.26%, (6610 of 22592)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAINING:   0%|          | 15/90367 [00:00<10:05, 149.16it/s, Epoch=5/100, Loss: 2.4299]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAINING:  22%|██▏       | 20027/90367 [02:00<07:43, 151.77it/s, Epoch=5/100, Loss: 0.2077] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAINING:  41%|████      | 37064/90367 [03:51<05:32, 160.23it/s, Epoch=5/100, Loss: 4.0344] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 38\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# assert False\u001b[39;00m\n\u001b[1;32m     37\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, target)\n\u001b[0;32m---> 38\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     40\u001b[0m pbar\u001b[38;5;241m.\u001b[39mset_postfix({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m})\n",
      "File \u001b[0;32m~/.conda/envs/deepV_a100/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/deepV_a100/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "class Config:\n",
    "    n_layer: int = 3\n",
    "    input_dim: int = 640\n",
    "    dropout: float = 0.0\n",
    "    bias: bool = False\n",
    "    n_labels: int = 17\n",
    "    pooling : str = 'mean'\n",
    "    norm_fn: nn.Module = nn.LayerNorm\n",
    "    position_embedding: bool = False\n",
    "    max_len: int = 30\n",
    "\n",
    "print('n labels:',nlabels)\n",
    "config = Config()\n",
    "config.n_labels = nlabels\n",
    "\n",
    "model = Classifier(config)\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    with tqdm(enumerate(train_loader), total=len(train_loader),desc='TRAINING') as pbar:\n",
    "        for batch_idx, (data, target) in pbar:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            # assert False\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            pbar.set_postfix({'Epoch':f'{epoch+1}/{num_epochs}, Loss: {loss.item():.4f}'})\n",
    "            if batch_idx % 20000 == 0:\n",
    "                print('')\n",
    "\n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data, target in tqdm(test_loader,desc='TESTING'):\n",
    "                output = model(data)\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                total += target.size(0)\n",
    "                correct += (predicted == target).sum().item()\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f'Test Accuracy: {accuracy:.2f}%, ({correct} of {total})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepV_a100",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
