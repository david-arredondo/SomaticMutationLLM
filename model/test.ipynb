{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dandreas/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from models import *\n",
    "from saveAndLoad import *\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_test(Dataset):\n",
    "    def __init__(self):\n",
    "        tlong = lambda x: torch.tensor(x, dtype=torch.long)\n",
    "        tlong2d = lambda x: torch.tensor([x], dtype=torch.long)\n",
    "        tfloat = lambda x: torch.tensor(x, dtype=torch.float32)\n",
    "        tfloat2d = lambda x: torch.tensor([x], dtype=torch.float32)\n",
    "        randemb = lambda: torch.rand(640)\n",
    "        \n",
    "        self.cancer = [tlong2d(1), tlong2d(3)]\n",
    "        self.sex = [tlong2d(0), tlong2d(1)]\n",
    "        self.age = [tfloat2d(42), tfloat2d(79)]\n",
    "        self.time = [tfloat2d(365), tfloat2d(491)]\n",
    "        self.event = [tlong2d(1), tlong2d(0)]\n",
    "        self.gene_ids = [\n",
    "            torch.stack([tlong(1), tlong(2), tlong(3)]),\n",
    "            torch.stack([tlong(4), tlong(5)])\n",
    "        ]\n",
    "        self.gene_emb = [\n",
    "            torch.stack([randemb(), randemb(), randemb()]),\n",
    "            torch.stack([randemb(),randemb()])\n",
    "            ]\n",
    "        self.maf = [\n",
    "            torch.stack([tfloat(.7), tfloat(.8), tfloat(.4)]),\n",
    "            torch.stack([tfloat(.05),tfloat(.2)])\n",
    "            ]\n",
    "        self.focal_cna_ids = [\n",
    "            torch.stack([tlong(1)]),\n",
    "            torch.stack([tlong(1), tlong(4), tlong(7)])\n",
    "        ]\n",
    "        self.focal_cna = [\n",
    "            torch.stack([tlong(0)]),\n",
    "            torch.stack([tlong(0), tlong(1), tlong(0)])\n",
    "        ]\n",
    "        # self.broad_cna = [                                #broad is binary\n",
    "        #     torch.tensor([], dtype=torch.long),\n",
    "        #     torch.stack([tlong(0), tlong(2), tlong(3)])\n",
    "        # ]\n",
    "\n",
    "        #--seg data--#\n",
    "        self.seg_ids = [\n",
    "            torch.stack([tlong(1), tlong(2)]),\n",
    "            torch.stack([tlong(4), tlong(5), tlong(14), tlong(23)])\n",
    "        ]\n",
    "        self.seg_start = [                              #broad is emb                   \n",
    "            torch.stack([tfloat(12345*3e-9), tfloat(123456*3e-9)]),\n",
    "            torch.stack([tfloat(54321*3e-9), tfloat(999321*3e-9), tfloat(123456789*3e-9), tfloat(123456789*3e-9)])\n",
    "        ]\n",
    "        self.seg_end = [                                #broad is emb\n",
    "            torch.stack([tfloat(12459*3e-9), tfloat(125555*3e-9)]),\n",
    "            torch.stack([tfloat(64321*3e-9), tfloat(1111321*3e-9), tfloat(123467890*3e-9) ,tfloat(123467890*3e-9)])\n",
    "        ]\n",
    "        self.seg_num_mark = [                           #broad is emb\n",
    "            torch.stack([tfloat(9), tfloat(51)]),\n",
    "            torch.stack([tfloat(3), tfloat(7), tfloat(11), tfloat(11)])\n",
    "        ]\n",
    "        self.seg_mean = [                               #broad is emb\n",
    "            torch.stack([tfloat(0.5), tfloat(-0.7)]),\n",
    "            torch.stack([tfloat(0.1), tfloat(-0.2), tfloat(0.3), tfloat(0.3)])\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.cancer)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        cancer = self.cancer[idx]\n",
    "        sex = self.sex[idx]\n",
    "        age = self.age[idx]\n",
    "        time = self.time[idx]\n",
    "        event = self.event[idx]\n",
    "        gene_id = self.gene_ids[idx]\n",
    "        gene_emb = self.gene_emb[idx]\n",
    "        maf = self.maf[idx]\n",
    "        focal_cna_id = self.focal_cna_ids[idx]\n",
    "        focal_cna = self.focal_cna[idx]\n",
    "        # broad_cna = self.broad_cna[idx] #broad is binary\n",
    "        seg_id = self.seg_ids[idx]\n",
    "        seg_start = self.seg_start[idx]\n",
    "        seg_end = self.seg_end[idx]\n",
    "        seg_num_mark = self.seg_num_mark[idx]\n",
    "        seg_mean = self.seg_mean[idx]\n",
    "        # return cancer, sex, age, time, event, gene_emb, maf, focal_cna, broad_cna                                 #broad is binary\n",
    "        return cancer, sex, age, time, event, gene_id, gene_emb, maf, focal_cna_id, focal_cna, seg_id, seg_start, seg_end, seg_num_mark, seg_mean  #broad is emb\n",
    "\n",
    "def collate_test(batch, config):\n",
    "    cancer =    torch.stack([item[0] for item in batch])\n",
    "    sex =       torch.stack([item[1] for item in batch])\n",
    "    age =       torch.stack([item[2] for item in batch])\n",
    "    time =      torch.stack([item[3] for item in batch])\n",
    "    event =     torch.stack([item[4] for item in batch])\n",
    "\n",
    "    def pad_and_mask(batch_, i, pad_val, mask = True):\n",
    "        unpadded_list = [item[i] for item in batch_]\n",
    "        padded_list = pad_sequence(unpadded_list, batch_first=True, padding_value=pad_val)\n",
    "        if mask:\n",
    "            lengths = [j.size(0) for j in unpadded_list]\n",
    "            max_length = padded_list.size(1)\n",
    "            # print('\\n-----------------')\n",
    "            # print('max_length',max_length)\n",
    "            # print('lengths',lengths)\n",
    "            # print('torch.arange(max_length).expand(len(lengths), max_length)\\n',torch.arange(max_length).expand(len(lengths), max_length))\n",
    "            mask = torch.arange(max_length).expand(len(lengths), max_length) >= torch.tensor(lengths).unsqueeze(1)\n",
    "            # print('torch.arange(max_length).expand(len(lengths), max_length) >= torch.tensor(lengths).unsqueeze(1)\\n', mask)\n",
    "            # print('-----------------\\n')\n",
    "            return padded_list, mask\n",
    "        return padded_list\n",
    "\n",
    "    gene_id =                       pad_and_mask(batch, 5, config.gene_id_vocab_size, mask = False)\n",
    "    gene_emb =                      pad_and_mask(batch, 6, 0, mask = False)\n",
    "    maf =                           pad_and_mask(batch, 7, 0, mask = False)\n",
    "    focal_cna_id =                  pad_and_mask(batch, 8, config.gene_id_vocab_size, mask = False)\n",
    "    focal_cna =                     pad_and_mask(batch, 9, config.focal_cna_vocab_size, mask = False)\n",
    "    # broad_cna, broad_cna_pad_mask = pad_and_mask(batch, 10, config.broad_cna_vocab_size) #broad is binary\n",
    "    \n",
    "    seg_id =                        pad_and_mask(batch, 10, config.seg_id_vocab_size, mask = False)\n",
    "    seg_start, seg_pad_mask =       pad_and_mask(batch, 11, 0)                      #broad is emb\n",
    "    seg_end =                       pad_and_mask(batch, 12, 0, mask = False)        #broad is emb\n",
    "    seg_num_mark =                  pad_and_mask(batch, 13, 0, mask = False)        #broad is emb\n",
    "    seg_mean =                      pad_and_mask(batch, 14, 0, mask = False)        #broad is emb\n",
    "\n",
    "    # return (cancer, sex, age, time, event, gene_emb, maf, focal_cna, broad_cna, pad_mask) #broad is binary\n",
    "    return (cancer, sex, age, time, event, gene_id, gene_emb, maf, focal_cna_id, focal_cna, seg_id, seg_start, seg_end, seg_num_mark, seg_mean, seg_pad_mask) #broad is emb\n",
    "\n",
    "class MLPProj(nn.Module):\n",
    "    def __init__(self, config, input_dim):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(input_dim, config.emb_dim)\n",
    "        self.lin2 = nn.Linear(config.embed_dim, config.emb_dim)\n",
    "        self.gelu = nn.GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.lin2(x)\n",
    "        return x\n",
    "\n",
    "class LinProj(nn.Module):\n",
    "    def __init__(self, config, input_dim):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(input_dim, config.emb_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lin1(x)\n",
    "\n",
    "class Rbf(nn.Module): #FROM ESM3\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.v_min, self.v_max, self.n_bins = config.rbf_params\n",
    "    \n",
    "    def rbf(self, values):\n",
    "        rbf_centers = torch.linspace(\n",
    "            self.v_min, self.v_max, self.n_bins, device=values.device, dtype=values.dtype\n",
    "        )\n",
    "        rbf_centers = rbf_centers.view([1] * len(values.shape) + [-1])\n",
    "        rbf_std = (self.v_max - self.v_min) / self.n_bins\n",
    "        z = (values.unsqueeze(-1) - rbf_centers) / rbf_std\n",
    "        rbf_encodings =  torch.exp(-(z**2))\n",
    "        return rbf_encodings\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.rbf(x)\n",
    "    \n",
    "class EmbedSurv_rbf_2heads(Rbf):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.v_min, self.v_max, self.n_bins = config.rbf_params\n",
    "        self.lin0 = nn.Linear(self.n_bins, config.emb_dim)\n",
    "        self.lin1 = nn.Linear(self.n_bins, config.emb_dim)\n",
    "        self.emb_dim = config.emb_dim  \n",
    "    \n",
    "    def forward(self, time, event):\n",
    "        time = time.squeeze(1)\n",
    "        event = event.squeeze(1)\n",
    "        output = torch.empty(time.size(0), self.emb_dim, device=time.device)\n",
    "        mask = event.bool()\n",
    "        rbf_encodings = self.rbf(time)\n",
    "        output[mask] = self.lin1(rbf_encodings[mask])\n",
    "        output[~mask] = self.lin0(rbf_encodings[~mask])\n",
    "        return output.unsqueeze(1)\n",
    "    \n",
    "class EmbedSurv_rbfTime_fuseEventEmb(Rbf):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.v_min, self.v_max, self.n_bins = config.rbf_params\n",
    "        self.lin = nn.Linear(self.n_bins, config.emb_dim)\n",
    "        self.embed_event = nn.Embedding(config.event_vocab_size, config.emb_dim)\n",
    "        self.embed_surv = config.lin_proj(config, input_dim = config.emb_dim*2)\n",
    "    \n",
    "    def forward(self, time, event):\n",
    "        time = time.squeeze(1)\n",
    "        event = event.squeeze(1)\n",
    "        time_emb = self.lin(self.rbf(time)).unsqueeze(1)\n",
    "        event_emb = self.embed_event(event).unsqueeze(1)\n",
    "        surv = torch.cat([time_emb, event_emb], dim=-1)     \n",
    "        surv_emb = self.embed_surv(surv)\n",
    "        print(surv_emb.shape)                    \n",
    "        return surv_emb\n",
    "    \n",
    "class EmbedSurv_linTime_fuseEventEmb(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.embed_time = config.lin_proj(config, input_dim = 1)\n",
    "        self.embed_event = nn.Embedding(config.event_vocab_size, config.emb_dim)\n",
    "        self.embed_surv = config.lin_proj(config, input_dim = config.emb_dim*2)\n",
    "    \n",
    "    def forward(self, time, event):\n",
    "        time = time.squeeze(1)\n",
    "        event = event.squeeze(1)\n",
    "        time_emb = self.embed_time(time).unsqueeze(1)\n",
    "        event_emb = self.embed_event(event).unsqueeze(1)\n",
    "        surv = torch.cat([time_emb, event_emb], dim=-1)     \n",
    "        surv_emb = self.embed_surv(surv)                    \n",
    "        return surv_emb\n",
    "                        \n",
    "class EmbedSurv_mlpEarlyFuse(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.embed_surv = config.lin_proj(config, input_dim = 2)\n",
    "    \n",
    "    def forward(self, time, event):\n",
    "        surv = torch.cat([time.unsqueeze(1), event.unsqueeze(1)], dim=-1)     \n",
    "        surv_emb = self.embed_surv(surv)                    \n",
    "        return surv_emb\n",
    "\n",
    "class Somatt(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.blocks = nn.ModuleList([Block_SelfAttention(config) for _ in range(config.n_layer)])\n",
    "        self.norm = config.norm_fn(config.emb_dim)\n",
    "\n",
    "        self.embed_cancer_type = nn.Embedding(config.cancer_type_vocab_size, config.emb_dim)\n",
    "        self.embed_sex = nn.Embedding(config.sex_vocab_size, config.emb_dim)\n",
    "        self.embed_age = config.lin_proj(config, input_dim = 1)\n",
    "        self.embed_surv = config.embed_surv(config)\n",
    "        self.embed_clin_id = nn.Embedding(config.n_clin_vars, config.emb_dim)\n",
    "        self.embed_gene = config.lin_proj(config, input_dim = config.emb_dim * 2)\n",
    "        self.embed_gene_id = nn.Embedding(config.gene_id_vocab_size+1, config.emb_dim, padding_idx=config.gene_id_vocab_size)\n",
    "        self.embed_maf = config.lin_proj(config, input_dim = 1)\n",
    "        self.embed_focal_cna = nn.Embedding(config.focal_cna_vocab_size+1, config.emb_dim, padding_idx=config.focal_cna_vocab_size)\n",
    "        self.embed_seg_id = nn.Embedding(config.seg_id_vocab_size+1, config.emb_dim, padding_idx=config.seg_id_vocab_size)\n",
    "        self.embed_seg = config.lin_proj(config, input_dim = 4)                                                                            #broad is emb\n",
    "        # self.embed_broad_cna = nn.Embedding(config.broad_cna_vocab_size+1, config.emb_dim, padding_idx=config.broad_cna_vocab_size)   #broad is binary                   \n",
    "\n",
    "        self.cancer_head = nn.Linear(config.emb_dim, config.cancer_type_vocab_size)\n",
    "        self.sex_head = nn.Linear(config.emb_dim, config.sex_vocab_size)\n",
    "        self.age_head = nn.Linear(config.emb_dim, 1)\n",
    "        self.survival_head = nn.Linear(config.emb_dim, 1)\n",
    "\n",
    "    def mean_pool_by_id(self, embs_, ids_):\n",
    "        B,N,emb_dim = embs_.shape\n",
    "\n",
    "        output = []\n",
    "        output_ids = []\n",
    "        for b in range(B):\n",
    "            ids = ids_[b]\n",
    "            embs = embs_[b]\n",
    "            unique_ids, inverse_indices = torch.unique(ids, sorted=True, return_inverse=True)\n",
    "            num_unique = unique_ids.size(0)\n",
    "            sum_emb = torch.zeros(num_unique, emb_dim, device=embs.device)\n",
    "            count   = torch.zeros(num_unique, device=embs.device)\n",
    "            sum_emb = sum_emb.scatter_add_(\n",
    "                0,\n",
    "                inverse_indices.unsqueeze(-1).expand(-1, emb_dim),\n",
    "                embs\n",
    "            )\n",
    "            count = count.scatter_add_(\n",
    "                0,\n",
    "                inverse_indices,\n",
    "                torch.ones_like(inverse_indices, dtype=torch.float)\n",
    "            )\n",
    "            emb_avg = sum_emb / count.unsqueeze(-1)\n",
    "            output.append(emb_avg)\n",
    "            output_ids.append(unique_ids)\n",
    "        output = pad_sequence(output, batch_first=True, padding_value=0)\n",
    "        output_ids = pad_sequence(output_ids, batch_first=True, padding_value=self.config.gene_id_vocab_size)\n",
    "        gene_pad_mask = output_ids == self.config.gene_id_vocab_size\n",
    "\n",
    "        return output, output_ids, gene_pad_mask\n",
    "\n",
    "    def forward(self, x, return_embedding=False):\n",
    "        # cancer, sex, age, time, event, gene, maf, focal_cna, broad_cna, pad_mask= x   #broad is binary\n",
    "        cancer, sex, age, time, event, gene_id, gene, maf, focal_cna_id, focal_cna, seg_id, seg_start, seg_end, seg_num_mark, seg_mean, seg_pad_mask= x     #broad is emb\n",
    "\n",
    "        #clinical\n",
    "        cancer_emb = self.embed_cancer_type(cancer)\n",
    "        sex_emb = self.embed_sex(sex)\n",
    "        age_emb = self.embed_age(age).unsqueeze(1)\n",
    "        surv_emb = self.embed_surv(time, event)\n",
    "\n",
    "        #gene\n",
    "        maf_emb = self.embed_maf(maf.unsqueeze(-1)) ##\n",
    "        gene_maf_cat = torch.cat([gene, maf_emb], dim=-1)\n",
    "        gene_emb = self.embed_gene(gene_maf_cat)\n",
    "        focal_cna_emb = self.embed_focal_cna(focal_cna)\n",
    "        \n",
    "        gene_avg = torch.cat([gene_emb, focal_cna_emb], dim=1)\n",
    "        gene_avg_ids = torch.cat([gene_id, focal_cna_id], dim=1)\n",
    "\n",
    "        gene_avg_emb, gene_avg_emb_ids, gene_pad_mask = self.mean_pool_by_id(gene_avg, gene_avg_ids)\n",
    "\n",
    "        # broad_cna_emb = self.embed_broad_cna(broad_cna)                       #broad is binary\n",
    "        seg = torch.stack([seg_start, seg_end, seg_num_mark, seg_mean], dim=-1) #broad is emb\n",
    "        seg_emb = self.embed_seg(seg)                                           #broad is emb\n",
    "\n",
    "        clin_pad_mask = torch.zeros(cancer.size(0), self.config.n_clin_vars, dtype=torch.bool)\n",
    "        pad_mask = torch.cat([clin_pad_mask, gene_pad_mask, seg_pad_mask], dim=1) #broad is emb\n",
    "\n",
    "        # tumor_emb = torch.cat([cancer_emb, sex_emb, age_emb, surv_emb, gene_summary_emb, focal_cna_emb, broad_cna_emb], dim=1) #broad is binary\n",
    "        tumor_emb = torch.cat([cancer_emb, sex_emb, age_emb, surv_emb, gene_avg_emb, seg_emb], dim=1)                        #broad is emb\n",
    "        clin_pos = self.embed_clin_id(torch.arange(self.config.n_clin_vars)).repeat(cancer.size(0), 1, 1)\n",
    "        gene_pos = self.embed_gene_id(gene_avg_emb_ids)\n",
    "        seg_pos = self.embed_seg_id(seg_id)\n",
    "        pos_emb = torch.cat([clin_pos, gene_pos, seg_pos], dim=1)\n",
    "        tumor_emb = tumor_emb + pos_emb\n",
    "\n",
    "        for block in self.blocks:\n",
    "            tumor_emb = block(tumor_emb, pad_mask=pad_mask)  # [B, G, emb_dim]\n",
    "\n",
    "        #set pad tokens emb to zero\n",
    "        tumor_emb = tumor_emb.masked_fill(pad_mask.unsqueeze(-1), 0)\n",
    "\n",
    "        logits = []\n",
    "        for i,head in enumerate([self.cancer_head, self.sex_head, self.age_head, self.survival_head]):\n",
    "            logits.append(head(tumor_emb[:,i,:]))\n",
    "\n",
    "        if return_embedding:\n",
    "            return logits, tumor_emb\n",
    "        return logits\n",
    "    \n",
    "## add mutational burden\n",
    "## trian model to predict effect of PARP inhibition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[-0.0271, -0.7561, -0.3086, -0.1538, -0.3338, -1.0484,  1.5290, -0.0858,\n",
      "         -0.4613,  0.3351],\n",
      "        [ 0.4723, -0.1167, -0.8101, -0.0554, -0.1427, -1.3444,  0.5201, -0.3321,\n",
      "          0.3887,  0.0783]], grad_fn=<AddmmBackward0>), tensor([[-0.7996,  0.1958],\n",
      "        [-0.8275,  1.1197]], grad_fn=<AddmmBackward0>), tensor([[-2.3932],\n",
      "        [-1.0468]], grad_fn=<AddmmBackward0>), tensor([[0.4423],\n",
      "        [0.5453]], grad_fn=<AddmmBackward0>)]\n"
     ]
    }
   ],
   "source": [
    "class Config_Somatt:\n",
    "    n_layer: int = 3\n",
    "    emb_dim: int = 640 #1152 esmC #1536 esm3 #640 esm2\n",
    "    input_dim: int = 640\n",
    "    dropout: float = 0.0\n",
    "    bias: bool = False\n",
    "    gene_id_vocab_size : int = 1433\n",
    "    cancer_type_vocab_size: int = 10\n",
    "    sex_vocab_size: int = 2\n",
    "    pooling : str = 'mean'\n",
    "    norm_fn: nn.Module = nn.LayerNorm\n",
    "    position_embedding: bool = False\n",
    "    num_heads: int = 1\n",
    "    lin_proj: nn.Module = LinProj\n",
    "    rbf_params = (0,1,16)\n",
    "    n_clin_vars: int = 4\n",
    "    seg_id_vocab_size: int = 46\n",
    "    broad_cna_vocab_size: int = 2   \n",
    "    focal_cna_vocab_size: int = 2   \n",
    "    event_vocab_size: int = 2\n",
    "    embed_surv: nn.Module = EmbedSurv_rbf_2heads\n",
    "\n",
    "config = Config_Somatt()\n",
    "model = Somatt(config)\n",
    "\n",
    "ds = Dataset_test()\n",
    "\n",
    "collate_test_with_config = partial(collate_test, config = config)\n",
    "loader = DataLoader(ds, batch_size=2, shuffle=True, collate_fn=collate_test_with_config)\n",
    "\n",
    "for batch in loader:\n",
    "    output = model(batch)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_dataset import Dataset_Assay, Dataset_Assay_Survival, custom_collate_assay, custom_collate_assay_survival, Dataset_Survival_MutationsOnly, Dataset_Classification_MutationsOnly\n",
    "\n",
    "def train_cancer_type(modelClass, configClass, dataset, data_df_emb, saveName, n_labels, n_folds=None, test_size = None, num_epochs = 15, lr = .0001, device = 'cuda:1'):\n",
    "\n",
    "    folds = getPatientGroupedLoaders(dataset, data_df_emb, n_folds=n_folds, test_size = test_size, batch_size = 250, collate=custom_collate_assay)\n",
    "\n",
    "    config_att = configClass()\n",
    "    config_att.n_labels = n_labels\n",
    "\n",
    "    print(data_df_emb[\"CANCER_TYPE_INT\"].unique())\n",
    "    print(\"Max label:\", data_df_emb[\"CANCER_TYPE_INT\"].max())\n",
    "    print(\"Min label:\", data_df_emb[\"CANCER_TYPE_INT\"].min())\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for i, (train_loader, test_loader) in enumerate(folds):\n",
    "        model = modelClass(config_att)\n",
    "        model.to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        print(f'\\nFOLD {i+1}')\n",
    "        if saveName is not None: saveName = './best_models/' + saveName.split('.')[0] + f'_fold{i+1}.pt'\n",
    "        train_assay(model,num_epochs,train_loader,test_loader, criterion, optimizer, saveName = saveName)\n",
    "\n",
    "\n",
    "def train_survival(modelClass, configClass, dataset, data_df_emb, saveName, n_folds = None, test_size = None, num_epochs = 5, lr = .0001, device = 'cuda:1'):\n",
    "\n",
    "    folds = getPatientGroupedLoaders(dataset, data_df_emb, n_folds=n_folds, test_size = test_size, batch_size = 100, collate=custom_collate_assay_survival)\n",
    "\n",
    "    config_att = configClass()\n",
    "    config_att.n_labels = 1\n",
    "\n",
    "    criterion = negative_log_partial_likelihood\n",
    "\n",
    "    for i, (train_loader, test_loader) in enumerate(folds):\n",
    "        model = modelClass(config_att)\n",
    "        model.to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        print(f'\\nFOLD {i+1}')\n",
    "        if saveName is not None: saveName = './best_models/' + saveName.split('.')[0] + f'_fold{i+1}.pt'\n",
    "        train_assay_survival(model,num_epochs,train_loader,test_loader, criterion, optimizer, saveName = saveName)\n",
    "\n",
    "def get_df(data_file, suffix = ''):\n",
    "    data_path = '../labeled_data/' + data_file\n",
    "    data_df_emb = pd.read_csv(data_path)\n",
    "    saveName =  f'model_sha_{data_file.split(\".\")[0]}_{suffix}.pt'\n",
    "    return data_df_emb, saveName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data from ../aa/tumors.pkl\n",
      "loading data from ../aa/assays.pkl\n"
     ]
    }
   ],
   "source": [
    "# mut_embeddings = np.load('/data/dandreas/SomaticMutationsLLM/aa/canonical_mut_cls_embeddings_esm3.npy')\n",
    "# ref_embeddings = np.load('/data/dandreas/SomaticMutationsLLM/aa/canonical_ref_cls_embeddings_esm3.npy')\n",
    "\n",
    "mut_embeddings = np.load('../aa/canonical_mut_norm_embeddings_esm2.npy')\n",
    "ref_embeddings = np.load('../aa/canonical_ref_embeddings_esm2.npy')\n",
    "\n",
    "# mut_embeddings = np.load('../aa/canonical_mut_norm_embeddings_esmC.npy')\n",
    "# ref_embeddings = np.load('../aa/canonical_ref_cls_embeddings_esmC.npy')\n",
    "\n",
    "tumors = pickleLoad('../aa/tumors.pkl')\n",
    "assays = pickleLoad('../aa/assays.pkl')\n",
    "device = 'cuda:1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143530 samples\n",
      "129608 unique patients\n",
      "20 labels\n",
      "n labels: 20\n"
     ]
    }
   ],
   "source": [
    "#CANCER TYPE\n",
    "data_df_emb, saveName = get_df('data_1_00percentMinCancerType.csv', suffix = 'MSK-IMPACT468')\n",
    "data_df_emb = data_df_emb[data_df_emb['assay']=='MSK-IMPACT468']\n",
    "dataset = Dataset_Assay(data_df_emb, 'CANCER_TYPE_INT', mut_embeddings, ref_embeddings, tumors, assays, device)\n",
    "# dataset = Dataset_Classification_MutationsOnly(data_df_emb, 'CANCER_TYPE_INT', mut_embeddings, tumors, device)\n",
    "n_labels = max(data_df_emb['CANCER_TYPE_INT'].unique())+1\n",
    "print('n labels:',n_labels)\n",
    "# train_cancer_type(Somatt, Config_Somatt, dataset, data_df_emb, saveName, n_labels, test_size = .2, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1392\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([5.7386e+04, 2.6433e+04, 1.4237e+04, 8.9300e+03, 5.5080e+03,\n",
       "        2.8690e+03, 1.3220e+03, 2.0000e+02, 7.0000e+00, 7.0000e+00]),\n",
       " array([1.000e+00, 4.930e+02, 9.850e+02, 1.477e+03, 1.969e+03, 2.461e+03,\n",
       "        2.953e+03, 3.445e+03, 3.937e+03, 4.429e+03, 4.921e+03]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAGhCAYAAACHw3XjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAtoklEQVR4nO3de3AVZZ7G8ScXzkm4nIRrQiRALBSI3CRAOONl1yXLUeOsjFAFLMtkEbVgAyNEuakT1JrdULgzisNN1x1j1cpw2RpwJBImFSSMErkEIgRIBhU3OHgSFJIDWUggefePqfRyBlSOBEJev5+qriL9/vrtt3+l5qm2uwkzxhgBAABYKry1FwAAAHA9EXYAAIDVCDsAAMBqhB0AAGA1wg4AALAaYQcAAFiNsAMAAKxG2AEAAFYj7AAAAKsRdgAAgNVCDjt//vOf9U//9E/q2rWroqOjNXjwYO3du9cZN8YoOztbPXv2VHR0tNLS0nT06NGgOU6dOqUpU6bI4/EoNjZW06dP19mzZ4NqDhw4oHvuuUdRUVFKTEzU0qVLL1vLhg0bNGDAAEVFRWnw4MF67733Qr0cAABguZDCzunTp3XXXXepXbt22rJliw4fPqxf/vKX6ty5s1OzdOlSvfrqq1q9erV27dqlDh06yOfz6fz5807NlClTdOjQIRUUFGjz5s3asWOHnnjiCWc8EAho7Nix6tOnj0pKSvTSSy/p+eef1+uvv+7U7Ny5U5MnT9b06dO1f/9+jRs3TuPGjVNZWdm19AMAAFgmLJS/CHThwoX68MMP9cc//vGK48YYJSQk6KmnntLTTz8tSaqtrVVcXJxyc3M1adIkHTlyRMnJydqzZ49GjBghScrPz9eDDz6oL774QgkJCVq1apWeffZZ+f1+uVwu59ybNm1SeXm5JGnixImqq6vT5s2bnfOPHj1aw4YN0+rVq6/qepqamnTixAl16tRJYWFhV9sGAADQiowxOnPmjBISEhQefhX3bUwIBg4caObMmWMmTJhgunfvboYNG2Zef/11Z/zTTz81ksz+/fuDjrv33nvNz372M2OMMf/5n/9pYmNjg8YvXLhgIiIizO9+9ztjjDFTp041Dz/8cFDNtm3bjCRz6tQpY4wxiYmJ5uWXXw6qyc7ONkOGDPnG9Z8/f97U1tY62+HDh40kNjY2NjY2tja4HT9+/KryS6RC8Nlnn2nVqlXKysrSM888oz179uhnP/uZXC6XMjIy5Pf7JUlxcXFBx8XFxTljfr9fPXr0CBqPjIxUly5dgmqSkpIum6N5rHPnzvL7/d96nivJycnRCy+8cNn+48ePy+PxXE0LAABAKwsEAkpMTFSnTp2uqj6ksNPU1KQRI0bo3/7t3yRJd955p8rKyrR69WplZGSEvtobbNGiRcrKynJ+bm6Wx+Mh7AAA0MZc7SMoIT2g3LNnTyUnJwftGzhwoCorKyVJ8fHxkqSqqqqgmqqqKmcsPj5e1dXVQeMXL17UqVOngmquNMel5/immubxK3G73U6wIeAAAPDDEFLYueuuu1RRURG0709/+pP69OkjSUpKSlJ8fLwKCwud8UAgoF27dsnr9UqSvF6vampqVFJS4tRs27ZNTU1NSk1NdWp27NihCxcuODUFBQXq37+/8+aX1+sNOk9zTfN5AAAAJCmkB5R3795tIiMjzb/+67+ao0ePmrffftu0b9/e/Nd//ZdTs2TJEhMbG2veeecdc+DAAfPwww+bpKQkc+7cOafm/vvvN3feeafZtWuX+eCDD8xtt91mJk+e7IzX1NSYuLg4M3XqVFNWVmbWrl1r2rdvb1577TWn5sMPPzSRkZHm3//9382RI0fM4sWLTbt27czBgwev+npqa2uNJFNbWxtKGwAAQCsK9fd3SGHHGGPeffddM2jQION2u82AAQOC3sYyxpimpibz85//3MTFxRm3223GjBljKioqgmq+/vprM3nyZNOxY0fj8XjMtGnTzJkzZ4JqPv74Y3P33Xcbt9ttbrnlFrNkyZLL1rJ+/Xpz++23G5fLZe644w6Tl5cX0rUQdgAAaHtC/f0d0nd2bBMIBBQTE6Pa2lqe3wEAoI0I9fc3fzcWAACwGmEHAABYjbADAACsRtgBAABWI+wAAACrEXYAAIDVCDsAAMBqhB0AAGA1wg4AALBaZGsvwFZ9F+a19hJC9vmS9NZeAgAALY47OwAAwGqEHQAAYDXCDgAAsBphBwAAWI2wAwAArEbYAQAAViPsAAAAqxF2AACA1Qg7AADAaoQdAABgNcIOAACwGmEHAABYjbADAACsRtgBAABWI+wAAACrEXYAAIDVCDsAAMBqhB0AAGA1wg4AALAaYQcAAFiNsAMAAKxG2AEAAFYj7AAAAKsRdgAAgNUIOwAAwGqEHQAAYDXCDgAAsBphBwAAWI2wAwAArEbYAQAAViPsAAAAqxF2AACA1Qg7AADAaoQdAABgNcIOAACwGmEHAABYjbADAACsRtgBAABWI+wAAACrEXYAAIDVQgo7zz//vMLCwoK2AQMGOOPnz59XZmamunbtqo4dO2r8+PGqqqoKmqOyslLp6elq3769evTooXnz5unixYtBNdu3b9fw4cPldrvVr18/5ebmXraWFStWqG/fvoqKilJqaqp2794dyqUAAIAfiJDv7Nxxxx368ssvne2DDz5wxubOnat3331XGzZsUFFRkU6cOKFHHnnEGW9sbFR6eroaGhq0c+dOvfXWW8rNzVV2drZTc+zYMaWnp+u+++5TaWmp5syZo8cee0xbt251atatW6esrCwtXrxY+/bt09ChQ+Xz+VRdXf19+wAAACwVZowxV1v8/PPPa9OmTSotLb1srLa2Vt27d9eaNWs0YcIESVJ5ebkGDhyo4uJijR49Wlu2bNFDDz2kEydOKC4uTpK0evVqLViwQCdPnpTL5dKCBQuUl5ensrIyZ+5JkyappqZG+fn5kqTU1FSNHDlSy5cvlyQ1NTUpMTFRs2fP1sKFC6/64gOBgGJiYlRbWyuPx3PVx12NvgvzWnS+G+HzJemtvQQAAL5TqL+/Q76zc/ToUSUkJOjWW2/VlClTVFlZKUkqKSnRhQsXlJaW5tQOGDBAvXv3VnFxsSSpuLhYgwcPdoKOJPl8PgUCAR06dMipuXSO5prmORoaGlRSUhJUEx4errS0NKcGAACgWWQoxampqcrNzVX//v315Zdf6oUXXtA999yjsrIy+f1+uVwuxcbGBh0TFxcnv98vSfL7/UFBp3m8eezbagKBgM6dO6fTp0+rsbHxijXl5eXfuv76+nrV19c7PwcCgau/eAAA0CaFFHYeeOAB589DhgxRamqq+vTpo/Xr1ys6OrrFF9fScnJy9MILL7T2MgAAwA10Ta+ex8bG6vbbb9cnn3yi+Ph4NTQ0qKamJqimqqpK8fHxkqT4+PjL3s5q/vm7ajwej6Kjo9WtWzdFRERcsaZ5jm+yaNEi1dbWOtvx48dDvmYAANC2XFPYOXv2rD799FP17NlTKSkpateunQoLC53xiooKVVZWyuv1SpK8Xq8OHjwY9NZUQUGBPB6PkpOTnZpL52iuaZ7D5XIpJSUlqKapqUmFhYVOzTdxu93yeDxBGwAAsFtIYefpp59WUVGRPv/8c+3cuVM/+clPFBERocmTJysmJkbTp09XVlaW3n//fZWUlGjatGnyer0aPXq0JGns2LFKTk7W1KlT9fHHH2vr1q167rnnlJmZKbfbLUmaMWOGPvvsM82fP1/l5eVauXKl1q9fr7lz5zrryMrK0n/8x3/orbfe0pEjRzRz5kzV1dVp2rRpLdgaAABgg5Ce2fniiy80efJkff311+revbvuvvtuffTRR+revbsk6eWXX1Z4eLjGjx+v+vp6+Xw+rVy50jk+IiJCmzdv1syZM+X1etWhQwdlZGToxRdfdGqSkpKUl5enuXPnatmyZerVq5feeOMN+Xw+p2bixIk6efKksrOz5ff7NWzYMOXn51/20DIAAEBI39mxDd/ZCcZ3dgAAbcF1/84OAABAW0LYAQAAViPsAAAAqxF2AACA1Qg7AADAaoQdAABgNcIOAACwGmEHAABYjbADAACsRtgBAABWI+wAAACrEXYAAIDVCDsAAMBqhB0AAGA1wg4AALAaYQcAAFiNsAMAAKxG2AEAAFYj7AAAAKsRdgAAgNUIOwAAwGqEHQAAYDXCDgAAsBphBwAAWI2wAwAArEbYAQAAViPsAAAAqxF2AACA1Qg7AADAaoQdAABgNcIOAACwGmEHAABYjbADAACsRtgBAABWI+wAAACrEXYAAIDVCDsAAMBqhB0AAGA1wg4AALAaYQcAAFiNsAMAAKxG2AEAAFYj7AAAAKsRdgAAgNUIOwAAwGqEHQAAYDXCDgAAsBphBwAAWI2wAwAArEbYAQAAViPsAAAAq11T2FmyZInCwsI0Z84cZ9/58+eVmZmprl27qmPHjho/fryqqqqCjqusrFR6errat2+vHj16aN68ebp48WJQzfbt2zV8+HC53W7169dPubm5l51/xYoV6tu3r6KiopSamqrdu3dfy+UAAAALfe+ws2fPHr322msaMmRI0P65c+fq3Xff1YYNG1RUVKQTJ07okUceccYbGxuVnp6uhoYG7dy5U2+99ZZyc3OVnZ3t1Bw7dkzp6em67777VFpaqjlz5uixxx7T1q1bnZp169YpKytLixcv1r59+zR06FD5fD5VV1d/30sCAAAWCjPGmFAPOnv2rIYPH66VK1fqF7/4hYYNG6ZXXnlFtbW16t69u9asWaMJEyZIksrLyzVw4EAVFxdr9OjR2rJlix566CGdOHFCcXFxkqTVq1drwYIFOnnypFwulxYsWKC8vDyVlZU555w0aZJqamqUn58vSUpNTdXIkSO1fPlySVJTU5MSExM1e/ZsLVy48KquIxAIKCYmRrW1tfJ4PKG24Vv1XZjXovPdCJ8vSW/tJQAA8J1C/f39ve7sZGZmKj09XWlpaUH7S0pKdOHChaD9AwYMUO/evVVcXCxJKi4u1uDBg52gI0k+n0+BQECHDh1yav56bp/P58zR0NCgkpKSoJrw8HClpaU5NVdSX1+vQCAQtAEAALtFhnrA2rVrtW/fPu3Zs+eyMb/fL5fLpdjY2KD9cXFx8vv9Ts2lQad5vHns22oCgYDOnTun06dPq7Gx8Yo15eXl37j2nJwcvfDCC1d3oQAAwAoh3dk5fvy4nnzySb399tuKioq6Xmu6bhYtWqTa2lpnO378eGsvCQAAXGchhZ2SkhJVV1dr+PDhioyMVGRkpIqKivTqq68qMjJScXFxamhoUE1NTdBxVVVVio+PlyTFx8df9nZW88/fVePxeBQdHa1u3bopIiLiijXNc1yJ2+2Wx+MJ2gAAgN1CCjtjxozRwYMHVVpa6mwjRozQlClTnD+3a9dOhYWFzjEVFRWqrKyU1+uVJHm9Xh08eDDoramCggJ5PB4lJyc7NZfO0VzTPIfL5VJKSkpQTVNTkwoLC50aAAAAKcRndjp16qRBgwYF7evQoYO6du3q7J8+fbqysrLUpUsXeTwezZ49W16vV6NHj5YkjR07VsnJyZo6daqWLl0qv9+v5557TpmZmXK73ZKkGTNmaPny5Zo/f74effRRbdu2TevXr1de3v+/4ZSVlaWMjAyNGDFCo0aN0iuvvKK6ujpNmzbtmhoCAADsEvIDyt/l5ZdfVnh4uMaPH6/6+nr5fD6tXLnSGY+IiNDmzZs1c+ZMeb1edejQQRkZGXrxxRedmqSkJOXl5Wnu3LlatmyZevXqpTfeeEM+n8+pmThxok6ePKns7Gz5/X4NGzZM+fn5lz20DAAAfti+13d2bMF3doLxnR0AQFtwQ76zAwAA0FYQdgAAgNUIOwAAwGqEHQAAYDXCDgAAsBphBwAAWI2wAwAArEbYAQAAViPsAAAAqxF2AACA1Qg7AADAaoQdAABgNcIOAACwGmEHAABYjbADAACsRtgBAABWI+wAAACrEXYAAIDVCDsAAMBqhB0AAGA1wg4AALAaYQcAAFiNsAMAAKxG2AEAAFYj7AAAAKsRdgAAgNUIOwAAwGqEHQAAYDXCDgAAsBphBwAAWI2wAwAArEbYAQAAViPsAAAAqxF2AACA1Qg7AADAaoQdAABgNcIOAACwGmEHAABYjbADAACsRtgBAABWI+wAAACrEXYAAIDVCDsAAMBqhB0AAGA1wg4AALAaYQcAAFiNsAMAAKxG2AEAAFYj7AAAAKsRdgAAgNVCCjurVq3SkCFD5PF45PF45PV6tWXLFmf8/PnzyszMVNeuXdWxY0eNHz9eVVVVQXNUVlYqPT1d7du3V48ePTRv3jxdvHgxqGb79u0aPny43G63+vXrp9zc3MvWsmLFCvXt21dRUVFKTU3V7t27Q7kUAADwAxFS2OnVq5eWLFmikpIS7d27V3/3d3+nhx9+WIcOHZIkzZ07V++++642bNigoqIinThxQo888ohzfGNjo9LT09XQ0KCdO3fqrbfeUm5urrKzs52aY8eOKT09Xffdd59KS0s1Z84cPfbYY9q6datTs27dOmVlZWnx4sXat2+fhg4dKp/Pp+rq6mvtBwAAsEyYMcZcywRdunTRSy+9pAkTJqh79+5as2aNJkyYIEkqLy/XwIEDVVxcrNGjR2vLli166KGHdOLECcXFxUmSVq9erQULFujkyZNyuVxasGCB8vLyVFZW5pxj0qRJqqmpUX5+viQpNTVVI0eO1PLlyyVJTU1NSkxM1OzZs7Vw4cKrXnsgEFBMTIxqa2vl8XiupQ2X6bswr0XnuxE+X5Le2ksAAOA7hfr7+3s/s9PY2Ki1a9eqrq5OXq9XJSUlunDhgtLS0pyaAQMGqHfv3iouLpYkFRcXa/DgwU7QkSSfz6dAIODcHSouLg6ao7mmeY6GhgaVlJQE1YSHhystLc2p+Sb19fUKBAJBGwAAsFvIYefgwYPq2LGj3G63ZsyYoY0bNyo5OVl+v18ul0uxsbFB9XFxcfL7/ZIkv98fFHSax5vHvq0mEAjo3Llz+uqrr9TY2HjFmuY5vklOTo5iYmKcLTExMdTLBwAAbUzIYad///4qLS3Vrl27NHPmTGVkZOjw4cPXY20tbtGiRaqtrXW248ePt/aSAADAdRYZ6gEul0v9+vWTJKWkpGjPnj1atmyZJk6cqIaGBtXU1ATd3amqqlJ8fLwkKT4+/rK3pprf1rq05q/f4KqqqpLH41F0dLQiIiIUERFxxZrmOb6J2+2W2+0O9ZIBAEAbds3f2WlqalJ9fb1SUlLUrl07FRYWOmMVFRWqrKyU1+uVJHm9Xh08eDDoramCggJ5PB4lJyc7NZfO0VzTPIfL5VJKSkpQTVNTkwoLC50aAACAZiHd2Vm0aJEeeOAB9e7dW2fOnNGaNWu0fft2bd26VTExMZo+fbqysrLUpUsXeTwezZ49W16vV6NHj5YkjR07VsnJyZo6daqWLl0qv9+v5557TpmZmc4dlxkzZmj58uWaP3++Hn30UW3btk3r169XXt7/v92UlZWljIwMjRgxQqNGjdIrr7yiuro6TZs2rQVbAwAAbBBS2KmurtZPf/pTffnll4qJidGQIUO0detW/f3f/70k6eWXX1Z4eLjGjx+v+vp6+Xw+rVy50jk+IiJCmzdv1syZM+X1etWhQwdlZGToxRdfdGqSkpKUl5enuXPnatmyZerVq5feeOMN+Xw+p2bixIk6efKksrOz5ff7NWzYMOXn51/20DIAAMA1f2enLeM7O8H4zg4AoC24Yd/ZAQAAaAsIOwAAwGqEHQAAYDXCDgAAsBphBwAAWI2wAwAArEbYAQAAViPsAAAAqxF2AACA1Qg7AADAaoQdAABgNcIOAACwGmEHAABYjbADAACsRtgBAABWi2ztBeDm0XdhXmsvIWSfL0lv7SUAAG5y3NkBAABWI+wAAACrEXYAAIDVCDsAAMBqhB0AAGA1wg4AALAaYQcAAFiNsAMAAKxG2AEAAFYj7AAAAKsRdgAAgNUIOwAAwGqEHQAAYDXCDgAAsBphBwAAWI2wAwAArEbYAQAAViPsAAAAqxF2AACA1Qg7AADAaoQdAABgNcIOAACwGmEHAABYjbADAACsRtgBAABWI+wAAACrEXYAAIDVCDsAAMBqhB0AAGA1wg4AALAaYQcAAFiNsAMAAKxG2AEAAFYj7AAAAKuFFHZycnI0cuRIderUST169NC4ceNUUVERVHP+/HllZmaqa9eu6tixo8aPH6+qqqqgmsrKSqWnp6t9+/bq0aOH5s2bp4sXLwbVbN++XcOHD5fb7Va/fv2Um5t72XpWrFihvn37KioqSqmpqdq9e3colwMAAH4AQgo7RUVFyszM1EcffaSCggJduHBBY8eOVV1dnVMzd+5cvfvuu9qwYYOKiop04sQJPfLII854Y2Oj0tPT1dDQoJ07d+qtt95Sbm6usrOznZpjx44pPT1d9913n0pLSzVnzhw99thj2rp1q1Ozbt06ZWVlafHixdq3b5+GDh0qn8+n6urqa+kHAACwTJgxxnzfg0+ePKkePXqoqKhI9957r2pra9W9e3etWbNGEyZMkCSVl5dr4MCBKi4u1ujRo7VlyxY99NBDOnHihOLi4iRJq1ev1oIFC3Ty5Em5XC4tWLBAeXl5Kisrc841adIk1dTUKD8/X5KUmpqqkSNHavny5ZKkpqYmJSYmavbs2Vq4cOFVrT8QCCgmJka1tbXyeDzftw1X1HdhXovOhyv7fEl6ay8BAHCDhfr7+5qe2amtrZUkdenSRZJUUlKiCxcuKC0tzakZMGCAevfureLiYklScXGxBg8e7AQdSfL5fAoEAjp06JBTc+kczTXNczQ0NKikpCSoJjw8XGlpaU4NAACAJEV+3wObmpo0Z84c3XXXXRo0aJAkye/3y+VyKTY2Nqg2Li5Ofr/fqbk06DSPN499W00gENC5c+d0+vRpNTY2XrGmvLz8G9dcX1+v+vp65+dAIBDCFQMAgLboe9/ZyczMVFlZmdauXduS67mucnJyFBMT42yJiYmtvSQAAHCdfa+wM2vWLG3evFnvv/++evXq5eyPj49XQ0ODampqguqrqqoUHx/v1Pz121nNP39XjcfjUXR0tLp166aIiIgr1jTPcSWLFi1SbW2tsx0/fjy0CwcAAG1OSGHHGKNZs2Zp48aN2rZtm5KSkoLGU1JS1K5dOxUWFjr7KioqVFlZKa/XK0nyer06ePBg0FtTBQUF8ng8Sk5OdmounaO5pnkOl8ullJSUoJqmpiYVFhY6NVfidrvl8XiCNgAAYLeQntnJzMzUmjVr9M4776hTp07OMzYxMTGKjo5WTEyMpk+frqysLHXp0kUej0ezZ8+W1+vV6NGjJUljx45VcnKypk6dqqVLl8rv9+u5555TZmam3G63JGnGjBlavny55s+fr0cffVTbtm3T+vXrlZf3/284ZWVlKSMjQyNGjNCoUaP0yiuvqK6uTtOmTWup3gAAAAuEFHZWrVolSfrbv/3boP1vvvmm/vmf/1mS9PLLLys8PFzjx49XfX29fD6fVq5c6dRGRERo8+bNmjlzprxerzp06KCMjAy9+OKLTk1SUpLy8vI0d+5cLVu2TL169dIbb7whn8/n1EycOFEnT55Udna2/H6/hg0bpvz8/MseWgYAAD9s1/SdnbaO7+y0fXxnBwB+eG7od3YAAABudoQdAABgNcIOAACwGmEHAABYjbADAACsRtgBAABWI+wAAACrEXYAAIDVCDsAAMBqhB0AAGA1wg4AALAaYQcAAFiNsAMAAKxG2AEAAFYj7AAAAKsRdgAAgNUIOwAAwGqEHQAAYDXCDgAAsBphBwAAWI2wAwAArEbYAQAAViPsAAAAqxF2AACA1Qg7AADAaoQdAABgNcIOAACwGmEHAABYjbADAACsFtnaCwCuRd+Fea29hJB9viS9tZcAAD8o3NkBAABWI+wAAACrEXYAAIDVCDsAAMBqhB0AAGA1wg4AALAaYQcAAFiNsAMAAKxG2AEAAFYj7AAAAKsRdgAAgNUIOwAAwGqEHQAAYDXCDgAAsBphBwAAWI2wAwAArEbYAQAAViPsAAAAqxF2AACA1Qg7AADAaoQdAABgtZDDzo4dO/TjH/9YCQkJCgsL06ZNm4LGjTHKzs5Wz549FR0drbS0NB09ejSo5tSpU5oyZYo8Ho9iY2M1ffp0nT17NqjmwIEDuueeexQVFaXExEQtXbr0srVs2LBBAwYMUFRUlAYPHqz33nsv1MsBAACWCzns1NXVaejQoVqxYsUVx5cuXapXX31Vq1ev1q5du9ShQwf5fD6dP3/eqZkyZYoOHTqkgoICbd68WTt27NATTzzhjAcCAY0dO1Z9+vRRSUmJXnrpJT3//PN6/fXXnZqdO3dq8uTJmj59uvbv369x48Zp3LhxKisrC/WSAACAxcKMMeZ7HxwWpo0bN2rcuHGS/nJXJyEhQU899ZSefvppSVJtba3i4uKUm5urSZMm6ciRI0pOTtaePXs0YsQISVJ+fr4efPBBffHFF0pISNCqVav07LPPyu/3y+VySZIWLlyoTZs2qby8XJI0ceJE1dXVafPmzc56Ro8erWHDhmn16tVXtf5AIKCYmBjV1tbK4/F83zZcUd+FeS06H+zx+ZL01l4CALRpof7+btFndo4dOya/36+0tDRnX0xMjFJTU1VcXCxJKi4uVmxsrBN0JCktLU3h4eHatWuXU3Pvvfc6QUeSfD6fKioqdPr0aafm0vM01zSf50rq6+sVCASCNgAAYLcWDTt+v1+SFBcXF7Q/Li7OGfP7/erRo0fQeGRkpLp06RJUc6U5Lj3HN9U0j19JTk6OYmJinC0xMTHUSwQAAG3MD+ptrEWLFqm2ttbZjh8/3tpLAgAA11mLhp34+HhJUlVVVdD+qqoqZyw+Pl7V1dVB4xcvXtSpU6eCaq40x6Xn+Kaa5vErcbvd8ng8QRsAALBbi4adpKQkxcfHq7Cw0NkXCAS0a9cueb1eSZLX61VNTY1KSkqcmm3btqmpqUmpqalOzY4dO3ThwgWnpqCgQP3791fnzp2dmkvP01zTfB4AAADpe4Sds2fPqrS0VKWlpZL+8lByaWmpKisrFRYWpjlz5ugXv/iFfv/73+vgwYP66U9/qoSEBOeNrYEDB+r+++/X448/rt27d+vDDz/UrFmzNGnSJCUkJEiS/vEf/1Eul0vTp0/XoUOHtG7dOi1btkxZWVnOOp588knl5+frl7/8pcrLy/X8889r7969mjVr1rV3BQAAWCMy1AP27t2r++67z/m5OYBkZGQoNzdX8+fPV11dnZ544gnV1NTo7rvvVn5+vqKiopxj3n77bc2aNUtjxoxReHi4xo8fr1dffdUZj4mJ0R/+8AdlZmYqJSVF3bp1U3Z2dtC3eH70ox9pzZo1eu655/TMM8/otttu06ZNmzRo0KDv1QgAAGCna/rOTlvHd3bQGvjODgBcm1B/f4d8ZwfAtWmrQZiQBqCt+kG9eg4AAH54CDsAAMBqhB0AAGA1wg4AALAaYQcAAFiNsAMAAKxG2AEAAFYj7AAAAKsRdgAAgNUIOwAAwGqEHQAAYDXCDgAAsBphBwAAWI2wAwAArEbYAQAAViPsAAAAqxF2AACA1Qg7AADAaoQdAABgtcjWXgCAtqHvwrzWXkLIPl+S3tpLAHAT4M4OAACwGmEHAABYjbADAACsRtgBAABWI+wAAACrEXYAAIDVCDsAAMBqhB0AAGA1wg4AALAaYQcAAFiNsAMAAKxG2AEAAFYj7AAAAKsRdgAAgNUIOwAAwGqEHQAAYLXI1l4AAFwvfRfmtfYSQvb5kvTWXgJgHe7sAAAAqxF2AACA1Qg7AADAaoQdAABgNcIOAACwGmEHAABYjbADAACsRtgBAABW46OCAHAT4UOIQMvjzg4AALAaYQcAAFiNsAMAAKzW5sPOihUr1LdvX0VFRSk1NVW7d+9u7SUBAICbSJsOO+vWrVNWVpYWL16sffv2aejQofL5fKqurm7tpQEAgJtEmw47v/rVr/T4449r2rRpSk5O1urVq9W+fXv95je/ae2lAQCAm0SbffW8oaFBJSUlWrRokbMvPDxcaWlpKi4uvuIx9fX1qq+vd36ura2VJAUCgRZfX1P9/7b4nABwM+o9d0NrLyFkZS/4WnsJuAbNv7eNMVdV32bDzldffaXGxkbFxcUF7Y+Li1N5efkVj8nJydELL7xw2f7ExMTrskYAwM0p5pXWXgFawpkzZxQTE/OddW027HwfixYtUlZWlvNzU1OTTp06pa5duyosLKzFzhMIBJSYmKjjx4/L4/G02Ly4Mvp949DrG4t+31j0+8a51l4bY3TmzBklJCRcVX2bDTvdunVTRESEqqqqgvZXVVUpPj7+ise43W653e6gfbGxsddrifJ4PPwLcwPR7xuHXt9Y9PvGot83zrX0+mru6DRrsw8ou1wupaSkqLCw0NnX1NSkwsJCeb3eVlwZAAC4mbTZOzuSlJWVpYyMDI0YMUKjRo3SK6+8orq6Ok2bNq21lwYAAG4SbTrsTJw4USdPnlR2drb8fr+GDRum/Pz8yx5avtHcbrcWL1582f8yw/VBv28cen1j0e8bi37fODe612Hmat/bAgAAaIPa7DM7AAAAV4OwAwAArEbYAQAAViPsAAAAqxF2roMVK1aob9++ioqKUmpqqnbv3t3aS7rp7dixQz/+8Y+VkJCgsLAwbdq0KWjcGKPs7Gz17NlT0dHRSktL09GjR4NqTp06pSlTpsjj8Sg2NlbTp0/X2bNng2oOHDige+65R1FRUUpMTNTSpUuv96XddHJycjRy5Eh16tRJPXr00Lhx41RRURFUc/78eWVmZqpr167q2LGjxo8ff9kHPCsrK5Wenq727durR48emjdvni5evBhUs337dg0fPlxut1v9+vVTbm7u9b68m86qVas0ZMgQ5+NpXq9XW7Zsccbp9fWzZMkShYWFac6cOc4++t1ynn/+eYWFhQVtAwYMcMZvql4btKi1a9cal8tlfvOb35hDhw6Zxx9/3MTGxpqqqqrWXtpN7b333jPPPvus+d3vfmckmY0bNwaNL1myxMTExJhNmzaZjz/+2PzDP/yDSUpKMufOnXNq7r//fjN06FDz0UcfmT/+8Y+mX79+ZvLkyc54bW2tiYuLM1OmTDFlZWXmt7/9rYmOjjavvfbajbrMm4LP5zNvvvmmKSsrM6WlpebBBx80vXv3NmfPnnVqZsyYYRITE01hYaHZu3evGT16tPnRj37kjF+8eNEMGjTIpKWlmf3795v33nvPdOvWzSxatMip+eyzz0z79u1NVlaWOXz4sPn1r39tIiIiTH5+/g293tb2+9//3uTl5Zk//elPpqKiwjzzzDOmXbt2pqyszBhDr6+X3bt3m759+5ohQ4aYJ5980tlPv1vO4sWLzR133GG+/PJLZzt58qQzfjP1mrDTwkaNGmUyMzOdnxsbG01CQoLJyclpxVW1LX8ddpqamkx8fLx56aWXnH01NTXG7Xab3/72t8YYYw4fPmwkmT179jg1W7ZsMWFhYebPf/6zMcaYlStXms6dO5v6+nqnZsGCBaZ///7X+YpubtXV1UaSKSoqMsb8pbft2rUzGzZscGqOHDliJJni4mJjzF/CaXh4uPH7/U7NqlWrjMfjcfo7f/58c8cddwSda+LEicbn813vS7rpde7c2bzxxhv0+jo5c+aMue2220xBQYH5m7/5Gyfs0O+WtXjxYjN06NArjt1sveZ/Y7WghoYGlZSUKC0tzdkXHh6utLQ0FRcXt+LK2rZjx47J7/cH9TUmJkapqalOX4uLixUbG6sRI0Y4NWlpaQoPD9euXbucmnvvvVcul8up8fl8qqio0OnTp2/Q1dx8amtrJUldunSRJJWUlOjChQtB/R4wYIB69+4d1O/BgwcHfcDT5/MpEAjo0KFDTs2lczTX/JD/XWhsbNTatWtVV1cnr9dLr6+TzMxMpaenX9YT+t3yjh49qoSEBN16662aMmWKKisrJd18vSbstKCvvvpKjY2Nl33BOS4uTn6/v5VW1fY19+7b+ur3+9WjR4+g8cjISHXp0iWo5kpzXHqOH5qmpibNmTNHd911lwYNGiTpL71wuVyX/SW5f93v7+rlN9UEAgGdO3fuelzOTevgwYPq2LGj3G63ZsyYoY0bNyo5OZleXwdr167Vvn37lJOTc9kY/W5Zqampys3NVX5+vlatWqVjx47pnnvu0ZkzZ266Xrfpvy4CwLXJzMxUWVmZPvjgg9ZeitX69++v0tJS1dbW6r//+7+VkZGhoqKi1l6WdY4fP64nn3xSBQUFioqKau3lWO+BBx5w/jxkyBClpqaqT58+Wr9+vaKjo1txZZfjzk4L6tatmyIiIi572ryqqkrx8fGttKq2r7l339bX+Ph4VVdXB41fvHhRp06dCqq50hyXnuOHZNasWdq8ebPef/999erVy9kfHx+vhoYG1dTUBNX/db+/q5ffVOPxeG66/xBeby6XS/369VNKSopycnI0dOhQLVu2jF63sJKSElVXV2v48OGKjIxUZGSkioqK9OqrryoyMlJxcXH0+zqKjY3V7bffrk8++eSm+2ebsNOCXC6XUlJSVFhY6OxrampSYWGhvF5vK66sbUtKSlJ8fHxQXwOBgHbt2uX01ev1qqamRiUlJU7Ntm3b1NTUpNTUVKdmx44dunDhglNTUFCg/v37q3PnzjfoalqfMUazZs3Sxo0btW3bNiUlJQWNp6SkqF27dkH9rqioUGVlZVC/Dx48GBQwCwoK5PF4lJyc7NRcOkdzDf8u/OW/C/X19fS6hY0ZM0YHDx5UaWmps40YMUJTpkxx/ky/r5+zZ8/q008/Vc+ePW++f7ZDepwZ32nt2rXG7Xab3Nxcc/jwYfPEE0+Y2NjYoKfNcbkzZ86Y/fv3m/379xtJ5le/+pXZv3+/+Z//+R9jzF9ePY+NjTXvvPOOOXDggHn44Yev+Or5nXfeaXbt2mU++OADc9tttwW9el5TU2Pi4uLM1KlTTVlZmVm7dq1p3779D+7V85kzZ5qYmBizffv2oFdG//d//9epmTFjhundu7fZtm2b2bt3r/F6vcbr9Trjza+Mjh071pSWlpr8/HzTvXv3K74yOm/ePHPkyBGzYsWKH+TruQsXLjRFRUXm2LFj5sCBA2bhwoUmLCzM/OEPfzDG0Ovr7dK3sYyh3y3pqaeeMtu3bzfHjh0zH374oUlLSzPdunUz1dXVxpibq9eEnevg17/+tendu7dxuVxm1KhR5qOPPmrtJd303n//fSPpsi0jI8MY85fXz3/+85+buLg443a7zZgxY0xFRUXQHF9//bWZPHmy6dixo/F4PGbatGnmzJkzQTUff/yxufvuu43b7Ta33HKLWbJkyY26xJvGlfosybz55ptOzblz58y//Mu/mM6dO5v27dubn/zkJ+bLL78Mmufzzz83DzzwgImOjjbdunUzTz31lLlw4UJQzfvvv2+GDRtmXC6XufXWW4PO8UPx6KOPmj59+hiXy2W6d+9uxowZ4wQdY+j19fbXYYd+t5yJEyeanj17GpfLZW655RYzceJE88knnzjjN1Ovw4wxJrR7QQAAAG0Hz+wAAACrEXYAAIDVCDsAAMBqhB0AAGA1wg4AALAaYQcAAFiNsAMAAKxG2AEAAFYj7AAAAKsRdgAAgNUIOwAAwGqEHQAAYLX/A8izYsOWNVdsAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "asdf = data_df_emb['time'][data_df_emb['time']>0]\n",
    "print(len(asdf[asdf>=3000]))\n",
    "asdf = asdf[asdf<=5000]\n",
    "plt.hist(asdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of embeddings per gene:\n",
      "tensor([[ 0.,  0.,  0.],\n",
      "        [ 7., 12., 17.],\n",
      "        [ 0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.],\n",
      "        [ 8., 10., 12.]])\n",
      "\n",
      "Count per gene:\n",
      "tensor([0., 3., 0., 0., 0., 2.])\n",
      "\n",
      "Averaged embeddings per gene:\n",
      "tensor([[   nan,    nan,    nan],\n",
      "        [2.3333, 4.0000, 5.6667],\n",
      "        [   nan,    nan,    nan],\n",
      "        [   nan,    nan,    nan],\n",
      "        [   nan,    nan,    nan],\n",
      "        [4.0000, 5.0000, 6.0000]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Dummy data: 5 embeddings, each of dimension 3.\n",
    "gene_emb = torch.tensor([\n",
    "    [1.0, 2.0, 3.0],  # embedding for sample 0\n",
    "    [4.0, 5.0, 6.0],  # sample 1\n",
    "    [7.0, 8.0, 9.0],  # sample 2\n",
    "    [1.0, 3.0, 5.0],  # sample 3\n",
    "    [2.0, 4.0, 6.0]   # sample 4\n",
    "])\n",
    "\n",
    "# Dummy gene IDs for each embedding.\n",
    "# For instance, gene ID 0 for samples 0 and 2, gene ID 1 for samples 1, 3, and 4.\n",
    "gene_ids = torch.tensor([5, 1, 5, 1, 1])\n",
    "\n",
    "# Determine the number of unique genes (assumes 0-indexed gene IDs)\n",
    "num_genes = gene_ids.max().item() + 1  # 2 in this case\n",
    "emb_dim = gene_emb.size(1)\n",
    "\n",
    "# Initialize tensors to accumulate sums and counts per gene.\n",
    "sum_embeddings = torch.zeros(num_genes, emb_dim)\n",
    "count_embeddings = torch.zeros(num_genes)\n",
    "\n",
    "# Expand gene_ids so that it matches the dimensions of gene_emb.\n",
    "# This tells scatter_add which rows in sum_embeddings to add to.\n",
    "indices = gene_ids.unsqueeze(-1).expand(-1, emb_dim)\n",
    "\n",
    "# Scatter-add the gene embeddings into the sum_embeddings tensor.\n",
    "sum_embeddings.scatter_add_(0, indices, gene_emb)\n",
    "\n",
    "# Count how many embeddings correspond to each gene ID.\n",
    "count_embeddings.scatter_add_(0, gene_ids, torch.ones_like(gene_ids, dtype=torch.float))\n",
    "\n",
    "# Compute the average embedding for each gene.\n",
    "gene_emb_avg = sum_embeddings / count_embeddings.unsqueeze(-1)\n",
    "\n",
    "print(\"Sum of embeddings per gene:\")\n",
    "print(sum_embeddings)\n",
    "print(\"\\nCount per gene:\")\n",
    "print(count_embeddings)\n",
    "print(\"\\nAveraged embeddings per gene:\")\n",
    "print(gene_emb_avg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
