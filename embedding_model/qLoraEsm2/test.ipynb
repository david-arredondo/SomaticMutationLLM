{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "# import wandb\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, matthews_corrcoef\n",
    "from transformers import (\n",
    "    AutoModel,\n",
    "    AutoTokenizer,\n",
    "    # DataCollatorForTokenClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from datasets import Dataset\n",
    "from accelerate import Accelerator\n",
    "from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType, prepare_model_for_kbit_training\n",
    "import pickle\n",
    "from saveAndLoad import *\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t30_150M_UR50D and are newly initialized: ['esm.pooler.dense.weight', 'esm.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EsmModel(\n",
       "  (embeddings): EsmEmbeddings(\n",
       "    (word_embeddings): Embedding(33, 640, padding_idx=1)\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (position_embeddings): Embedding(1026, 640, padding_idx=1)\n",
       "  )\n",
       "  (encoder): EsmEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-29): 30 x EsmLayer(\n",
       "        (attention): EsmAttention(\n",
       "          (self): EsmSelfAttention(\n",
       "            (query): Linear(in_features=640, out_features=640, bias=True)\n",
       "            (key): Linear(in_features=640, out_features=640, bias=True)\n",
       "            (value): Linear(in_features=640, out_features=640, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (rotary_embeddings): RotaryEmbedding()\n",
       "          )\n",
       "          (output): EsmSelfOutput(\n",
       "            (dense): Linear(in_features=640, out_features=640, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (intermediate): EsmIntermediate(\n",
       "          (dense): Linear(in_features=640, out_features=2560, bias=True)\n",
       "        )\n",
       "        (output): EsmOutput(\n",
       "          (dense): Linear(in_features=2560, out_features=640, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (LayerNorm): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (emb_layer_norm_after): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (pooler): EsmPooler(\n",
       "    (dense): Linear(in_features=640, out_features=640, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       "  (contact_head): EsmContactPredictionHead(\n",
       "    (regression): Linear(in_features=600, out_features=1, bias=True)\n",
       "    (activation): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = 'facebook/esm2_t30_150M_UR50D'\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModel.from_pretrained(checkpoint).to('cuda')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data from ../../aa/canonical_mut.pkl\n",
      "loading data from ../../aa/canonical_ref.pkl\n"
     ]
    }
   ],
   "source": [
    "seqs = pickleLoad('../../aa/canonical_mut.pkl')\n",
    "refs = pickleLoad('../../aa/canonical_ref.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "656995"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutSeqSet = set(seqs)\n",
    "len(mutSeqSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1433"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refSeqSet = set(refs)\n",
    "len(refSeqSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14509\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    idx = 569032\n",
    "    print(len(seqs[idx]))\n",
    "    inputs = tokenizer(seqs[idx])\n",
    "    ids = torch.tensor([inputs['input_ids']]).to('cuda')\n",
    "    att = torch.tensor([inputs['attention_mask']]).to('cuda')\n",
    "    output = model(ids, attention_mask=att)\n",
    "    print(len(ids))\n",
    "    output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data from ../../aa/idxMap_canonical_mut_to_ref.pkl\n",
      "928\n",
      "928\n",
      "tensor([1.0000])\n",
      "0.065024815 0.0650314\n",
      "0.26945215 0.26973447\n",
      "0.11472979 0.115435004\n",
      "0.22270499 0.22282611\n",
      "0.123758435 0.12371794\n",
      "-0.16197532 -0.16178976\n",
      "0.06918807 0.07076595\n",
      "0.044536114 0.045179795\n",
      "-0.09739348 -0.09797263\n",
      "-0.12477154 -0.123642206\n",
      "0.015398634 0.015090378\n",
      "0.11419302 0.11459662\n",
      "-0.06595691 -0.06460882\n",
      "-0.011293549 -0.011246576\n",
      "-0.12015294 -0.12091027\n",
      "0.038723208 0.039486215\n",
      "-0.0009982433 -0.0009895485\n",
      "0.18213648 0.18227133\n",
      "0.1296329 0.12970518\n",
      "-0.24497712 -0.24443491\n",
      "-0.1895033 -0.19017214\n",
      "0.07730589 0.07757619\n",
      "-0.017968405 -0.018914307\n",
      "0.14176086 0.14151566\n",
      "-0.06627409 -0.065241754\n",
      "-0.075001255 -0.074546695\n",
      "-0.10816459 -0.107831396\n",
      "0.10311163 0.10303631\n",
      "0.08187747 0.08124441\n",
      "0.14174916 0.14173748\n",
      "0.15100494 0.15118705\n",
      "-0.13025278 -0.13047566\n",
      "-0.29223242 -0.29288253\n",
      "-0.1458308 -0.14635356\n",
      "0.0818969 0.08190235\n",
      "-0.18994533 -0.19003633\n",
      "-0.00015120208 0.00085328496\n",
      "-0.44124052 -0.44161108\n",
      "-0.041721288 -0.042967476\n",
      "0.240139 0.24062942\n",
      "-0.086787246 -0.08660524\n",
      "-0.14079395 -0.14028144\n",
      "-0.17945378 -0.18026972\n",
      "0.111397564 0.110162094\n",
      "-0.14495787 -0.1440293\n",
      "0.2710958 0.2705473\n",
      "-0.045181368 -0.045190334\n",
      "0.3904247 0.39045778\n",
      "0.17514105 0.17506355\n",
      "-0.27501035 -0.27435473\n"
     ]
    }
   ],
   "source": [
    "ref_idx_map = pickleLoad('../../aa/idxMap_canonical_mut_to_ref.pkl')\n",
    "idx = 54\n",
    "with torch.no_grad():\n",
    "    print(len(seqs[idx]))\n",
    "    inputs = tokenizer(seqs[idx])\n",
    "    ids = torch.tensor([inputs['input_ids']]).to('cuda')\n",
    "    att = torch.tensor([inputs['attention_mask']]).to('cuda')\n",
    "    output0 = model(ids, attention_mask=att)\n",
    "    output0 = output0['pooler_output'].detach().to('cpu').numpy()[0]\n",
    "\n",
    "with torch.no_grad():\n",
    "    idx = ref_idx_map[idx]\n",
    "    print(len(refs[idx]))\n",
    "    inputs = tokenizer(refs[idx])\n",
    "    ids = torch.tensor([inputs['input_ids']]).to('cuda')\n",
    "    att = torch.tensor([inputs['attention_mask']]).to('cuda')\n",
    "    output1 = model(ids, attention_mask=att)\n",
    "    output1 = output1['pooler_output'].detach().to('cpu').numpy()[0]\n",
    "\n",
    "print(F.cosine_similarity(torch.tensor(output0).unsqueeze(0),torch.tensor(output1).unsqueeze(0)))\n",
    "\n",
    "for i,j in zip(output0[:50],output1[:50]):\n",
    "    print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 14511, 640])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['last_hidden_state'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 640])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['pooler_output'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float32"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output['pooler_output'].detach().to('cpu').numpy()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 976\n",
      "54 928\n",
      "57 976\n",
      "59 976\n",
      "83 976\n",
      "\n",
      " 14511 568862 \n",
      "\n",
      "[5809, 5883, 5889, 5890, 8789, 8794, 8795, 8796, 8797, 8798, 14506, 14507, 14508, 14509, 14511]\n"
     ]
    }
   ],
   "source": [
    "max=5\n",
    "n=0\n",
    "longest = 0\n",
    "longest_i = 0\n",
    "lens = set()\n",
    "for ni,i in enumerate(seqs):\n",
    "    if i is None: continue\n",
    "    lens.add(len(i))\n",
    "    if len(i)>longest:\n",
    "        longest = len(i)\n",
    "        longest_i = ni\n",
    "    if 900<len(i)<1000:\n",
    "        if n<max:\n",
    "            print(ni, len(i))\n",
    "            n+=1\n",
    "print('\\n',longest,longest_i,'\\n')\n",
    "print(sorted(list(lens))[-15:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepV_a100",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
